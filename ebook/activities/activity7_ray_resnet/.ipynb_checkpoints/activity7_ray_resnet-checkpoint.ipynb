{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75c8ac9-b947-4dc9-9eb8-3bcd2c9662eb",
   "metadata": {},
   "source": [
    "### Exercise 9: Communicating Ray Actors\n",
    "\n",
    "This is a short exercise to demonstrate how actors can communicate through remote oids.\n",
    "We are going to break the actors of the ImageNet classification [Example XX](RayImageNet.ipynb) into \n",
    "two actors: one that transforms the image into an ResNet50 compatible tensor and one that takes\n",
    "the tensor as input and returns the classification. \n",
    "\n",
    "You have been given two class files that have been written to be instantiated as Ray actors:\n",
    "  * [rayresnet50_normalize](../rayresnet50_normalize.py)\n",
    "  * [rayresnet50_classify](../rayresnet50_classify.py)\n",
    "\n",
    "To complete the exercise you need to populate the following driver code.  Then answer the questions.\n",
    "\n",
    "Data is from https://github.com/EliSchwartz/imagenet-sample-images.\n",
    "\n",
    "Note: check your ouput to make sure that the predictions match the input file. This classifier should be over 90% correct. You need to be careful to match the return OIDs with files. **Include the cell output in submitted notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39ff1e-03fe-4853-8039-d2dea50c019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-21 13:57:55,478 E 50193 50193] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 12aef49e3dad32fa5cece715ef101724805c05e000e37b633063df5c, IP: 172.17.0.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.2`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "from rayresnet50_normalize import RRN50Normalize\n",
    "from rayresnet50_classify import RRN50Classify\n",
    "import ray\n",
    "import time\n",
    "import os\n",
    "\n",
    "num_actors=4\n",
    "\n",
    "# script to drive parallel program\n",
    "ray.init(num_cpus=num_actors, ignore_reinit_error=True)\n",
    "\n",
    "### TODO instantiate 4 normalization actors\n",
    "\n",
    "### TODO instantiate 4 classification actors\n",
    "\n",
    "\n",
    "directory = '../data/imagenet1000'\n",
    "files = os.listdir(directory)\n",
    "\n",
    "start_time = time.time()  # Get the current time\n",
    "\n",
    "for i in range(len(files)):\n",
    "    if files[i].endswith(\".JPEG\"):\n",
    "        file_path = os.path.join(directory, files[i])\n",
    "\n",
    "        ### TODO call remote to normalize image into tensor\n",
    "        \n",
    "        ### TODO call remote to classify tensor\n",
    "        \n",
    "        ### TODO store the oids needed to complete the computation\n",
    "        \n",
    "for i in range(len(files)):\n",
    "    try:\n",
    "        ### TODO collect results for each file in a variable preds\n",
    "        # preds = ray.get(....)\n",
    "        # print(f\"Filename {files[i]}: predictions {preds}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "end_time = time.time()  # Get the current time again\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time: \", execution_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f80ddb-2308-4a0f-970b-8121ab1de586",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Answer these questions inline in this markdown cell.\n",
    "\n",
    "* Question 1: Does the computation for a single input file (normalization and classification) run in serial or parallel?  If serially, how is the dependency enforced?\n",
    "\n",
    "* Question 2: Does the computation of different files run in serial or parallel?  If parallel, explain why they are independent. \n",
    "\n",
    "* Question 3: Your computation needs to collect return identifiers for the classification objects. It is not necessary to collect the OIDs of the normalization function in the driver code. Why?\n",
    "\n",
    "* Question 4: At any given point in time, how many actors are running and what are they doing?=\n",
    "\n",
    "* Question 5: Is this implementation faster or slower than doing the same work in one actor?  Can you think of a situation in which it would be faster to decompose the code?  (By situation, I mean data properties or target hardware system on which this would be prefereable.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1bcc4d-1bd9-45eb-bf74-bea3530e8a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7e5f4-6a48-4e2b-a9c4-b2c66b98b3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
